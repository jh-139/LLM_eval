{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#https://qwen.readthedocs.io/en/latest/inference/chat.html\n#https://www.philschmid.de/fine-tune-llms-in-2024-with-trl#3-create-and-prepare-the-dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-17T13:35:27.584900Z","iopub.execute_input":"2024-10-17T13:35:27.585318Z","iopub.status.idle":"2024-10-17T13:35:27.589784Z","shell.execute_reply.started":"2024-10-17T13:35:27.585280Z","shell.execute_reply":"2024-10-17T13:35:27.588839Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# https://explainshell.com/explain?cmd=tree+.+--charset+utf-8+-d+-L+2\n\n#!tree . --charset utf-8 -d -L 2\n!tree --charset utf-8 -d -L 2","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:54:16.311800Z","iopub.execute_input":"2024-10-19T03:54:16.312217Z","iopub.status.idle":"2024-10-19T03:54:17.312470Z","shell.execute_reply.started":"2024-10-19T03:54:16.312171Z","shell.execute_reply":"2024-10-19T03:54:17.311294Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\u001b[01;34m.\u001b[0m\n├── \u001b[01;34mcommonsense_qa\u001b[0m\n│   ├── \u001b[01;34mtest\u001b[0m\n│   ├── \u001b[01;34mtrain\u001b[0m\n│   └── \u001b[01;34mvalidation\u001b[0m\n├── \u001b[01;34mmodels\u001b[0m\n│   ├── \u001b[01;34mQwen2-0.5B\u001b[0m\n│   ├── \u001b[01;34mQwen2-7B\u001b[0m\n│   ├── \u001b[01;34mQwen2.5-0.5B\u001b[0m\n│   └── \u001b[01;34mQwen2.5-0.5B-Instruct\u001b[0m\n├── \u001b[01;34mqwen2.5:0.5B-Cot0-val\u001b[0m\n├── \u001b[01;34mqwen2.5:0.5B-Instruct-Cot0-val\u001b[0m\n├── \u001b[01;34mqwen2:0.5B-Cot0-val\u001b[0m\n├── \u001b[01;34mqwen2:0.5B-Cot0optimised1-val\u001b[0m\n├── \u001b[01;34mqwen2:0.5B-Cot0optimised2-val\u001b[0m\n├── \u001b[01;34mqwen2:0.5B-icl5-val\u001b[0m\n├── \u001b[01;34mqwen2:0.5B-icl8-val\u001b[0m\n├── \u001b[01;34mqwen2:0.5B-standard-val\u001b[0m\n└── \u001b[01;34mqwen2:7B-standard-val\u001b[0m\n\n18 directories\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline\nfrom datasets import load_dataset, load_from_disk\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-10-18T03:13:02.262415Z","iopub.execute_input":"2024-10-18T03:13:02.262792Z","iopub.status.idle":"2024-10-18T03:13:21.661532Z","shell.execute_reply.started":"2024-10-18T03:13:02.262752Z","shell.execute_reply":"2024-10-18T03:13:21.660581Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# load model\nmodel_name = \"Qwen2-0.5B\"\n#model_name = \"Qwen2-7B\"\n\nmodels_dir = \"models\"\nif not os.path.exists(models_dir):\n    os.mkdir(models_dir)\n\nif not os.path.exists(os.path.join(models_dir,model_name)):\n    pipe = pipeline(\"text-generation\", f\"Qwen/{model_name}\", torch_dtype=\"auto\", device_map=\"auto\")\n    pipe.tokenizer.padding_side=\"left\"\n    pipe.save_pretrained(os.path.join(models_dir,model_name))\n\nelse:\n    print(\"Load from disk\")\n    pipe = pipeline(\"text-generation\", os.path.join(models_dir,model_name), torch_dtype=\"auto\", device_map=\"auto\")\n    pipe.tokenizer.padding_side=\"left\"\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-18T03:14:40.062598Z","iopub.execute_input":"2024-10-18T03:14:40.063483Z","iopub.status.idle":"2024-10-18T03:14:41.655276Z","shell.execute_reply.started":"2024-10-18T03:14:40.063442Z","shell.execute_reply":"2024-10-18T03:14:41.654427Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Load from disk\n","output_type":"stream"}]},{"cell_type":"code","source":"def send_prompt_to_LLM(prompt):\n    \n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response_message = pipe(messages, max_new_tokens=512)[0][\"generated_text\"][-1]\n    #messages.append({\"role\": \"user\", \"content\": prompt})\n    #response_message = pipe(messages, max_new_tokens=512)[0][\"generated_text\"][-1]\n    \n    response_message = response_message['content']\n    return response_message","metadata":{"execution":{"iopub.status.busy":"2024-10-18T03:14:46.320260Z","iopub.execute_input":"2024-10-18T03:14:46.321028Z","iopub.status.idle":"2024-10-18T03:14:46.326460Z","shell.execute_reply.started":"2024-10-18T03:14:46.320987Z","shell.execute_reply":"2024-10-18T03:14:46.325413Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# load dataset\ndataset_name_hub = \"tau/commonsense_qa\"\ndataset_local_dir = \"commonsense_qa\"\n\nif not os.path.exists(dataset_local_dir):\n    commonsenseQA = load_dataset(dataset_name_hub)\n    commonsenseQA.save_to_disk(dataset_local_dir)\nelse:\n    print(\"Load from disk\")\n    commonsenseQA = load_from_disk(dataset_local_dir)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T03:14:48.306929Z","iopub.execute_input":"2024-10-18T03:14:48.307834Z","iopub.status.idle":"2024-10-18T03:14:48.345017Z","shell.execute_reply.started":"2024-10-18T03:14:48.307789Z","shell.execute_reply":"2024-10-18T03:14:48.344109Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Load from disk\n","output_type":"stream"}]},{"cell_type":"code","source":"for i,row in enumerate(commonsenseQA['validation']):\n    if i == 8:\n        break\n    print(row)\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-10-18T03:14:50.697199Z","iopub.execute_input":"2024-10-18T03:14:50.697939Z","iopub.status.idle":"2024-10-18T03:14:50.710422Z","shell.execute_reply.started":"2024-10-18T03:14:50.697902Z","shell.execute_reply":"2024-10-18T03:14:50.709393Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{'id': '1afa02df02c908a558b4036e80242fac', 'question': 'A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?', 'question_concept': 'revolving door', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['bank', 'library', 'department store', 'mall', 'new york']}, 'answerKey': 'A'}\n\n\n{'id': 'a7ab086045575bb497933726e4e6ad28', 'question': 'What do people aim to do at work?', 'question_concept': 'people', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['complete job', 'learn from each other', 'kill animals', 'wear hats', 'talk to each other']}, 'answerKey': 'A'}\n\n\n{'id': 'b8c0a4703079cf661d7261a60a1bcbff', 'question': 'Where would you find magazines along side many other printed works?', 'question_concept': 'magazines', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['doctor', 'bookstore', 'market', 'train station', 'mortuary']}, 'answerKey': 'B'}\n\n\n{'id': 'e68fb2448fd74e402aae9982aa76e527', 'question': 'Where are  you likely to find a hamburger?', 'question_concept': 'hamburger', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['fast food restaurant', 'pizza', 'ground up dead cows', 'mouth', 'cow carcus']}, 'answerKey': 'A'}\n\n\n{'id': '2435de612dd69f2012b9e40d6af4ce38', 'question': 'James was looking for a good place to buy farmland.  Where might he look?', 'question_concept': 'farmland', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['midwest', 'countryside', 'estate', 'farming areas', 'illinois']}, 'answerKey': 'A'}\n\n\n{'id': 'a4892551cb4beb279653ae52d0de4c89', 'question': 'What island country is ferret popular?', 'question_concept': 'ferret', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['own home', 'north carolina', 'great britain', 'hutch', 'outdoors']}, 'answerKey': 'C'}\n\n\n{'id': '118a9093a30695622363455e4d911866', 'question': 'In what Spanish speaking North American country can you get a great cup of coffee?', 'question_concept': 'cup of coffee', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': [\"mildred's coffee shop\", 'mexico', 'diner', 'kitchen', 'canteen']}, 'answerKey': 'B'}\n\n\n{'id': '05ea49b82e8ec519e82d6633936ab8bf', 'question': 'What do animals do when an enemy is approaching?', 'question_concept': 'animals', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['feel pleasure', 'procreate', 'pass water', 'listen to each other', 'sing']}, 'answerKey': 'D'}\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Prompts**","metadata":{}},{"cell_type":"markdown","source":"#### **Standard**","metadata":{}},{"cell_type":"code","source":"def create_standard_prompt(row):\n    \n    question_para = f\"\\nQ: {row['question']}\"\n    \n    options_para = '\\noptions: '\n    for label, text in zip(row['choices']['label'], row['choices']['text']):\n        options_para = options_para + f\" ({label}) {text}\"\n        \n    prompt =  f\"Answer the following multiple choice question: {question_para} {options_para}\"\n    return prompt\n\nprint(create_standard_prompt(row))","metadata":{"execution":{"iopub.status.busy":"2024-10-18T03:20:25.358204Z","iopub.execute_input":"2024-10-18T03:20:25.359234Z","iopub.status.idle":"2024-10-18T03:20:25.366970Z","shell.execute_reply.started":"2024-10-18T03:20:25.359179Z","shell.execute_reply":"2024-10-18T03:20:25.365857Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Answer the following multiple choice question: \nQ: Reading newspaper one of many ways to practice your what? \noptions:  (A) literacy (B) knowing how to read (C) money (D) buying (E) money bank\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **Chain-of_Thought 0 shot**","metadata":{}},{"cell_type":"code","source":"def create_CoT0shot_prompt(row):\n    \n    question_para = f\"\\nQ: {row['question']}\"\n    \n    options_para = '\\noptions: '\n    for label, text in zip(row['choices']['label'], row['choices']['text']):\n        options_para = options_para + f\" ({label}) {text}\"\n        \n    CoT_para = f\"\\n\\nLet's think step by step before arriving at the final answer.\"\n    \n    prompt =  f\"Answer the following multiple choice question: \\n{question_para} {options_para} {CoT_para}\"\n    return prompt\n\nprint(create_CoT0shot_prompt(row))","metadata":{"execution":{"iopub.status.busy":"2024-10-18T03:20:26.811592Z","iopub.execute_input":"2024-10-18T03:20:26.811980Z","iopub.status.idle":"2024-10-18T03:20:26.818824Z","shell.execute_reply.started":"2024-10-18T03:20:26.811941Z","shell.execute_reply":"2024-10-18T03:20:26.817909Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Answer the following multiple choice question: \n\nQ: Reading newspaper one of many ways to practice your what? \noptions:  (A) literacy (B) knowing how to read (C) money (D) buying (E) money bank \n\nLet's think step by step before arriving at the final answer.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **Chain-of_Thought 0 shot optimised**","metadata":{}},{"cell_type":"code","source":"def create_CoT0shotoptimised1_prompt(row):\n    \n    question_para = f\"\\nQ: {row['question']}\"\n    \n    options_para = '\\noptions: '\n    for label, text in zip(row['choices']['label'], row['choices']['text']):\n        options_para = options_para + f\" ({label}) {text}\"\n        \n    CoT_para = f\"\\n\\nLet's think step by step before arriving at the final answer. \"\n    CoT_para =  CoT_para + f\"\\nStep 1. Consider each option given one by one, for each option assume the option is the answer to the question, and use the option to answer the question.\"\n    CoT_para =  CoT_para + f\"\\nStep 2. Pick which one of the 5 answer makes the most sense.\"\n    CoT_para =  CoT_para + f\"\\nStep 3. Answer the mutiple choice question with the previous insights from Step 1 and Step 2.\"\n    \n    prompt =  f\"Answer the following multiple choice question: \\n{question_para} {options_para} {CoT_para}\"\n    return prompt\n\nprint(create_CoT0shotoptimised1_prompt(row))","metadata":{"execution":{"iopub.status.busy":"2024-10-18T03:20:28.245530Z","iopub.execute_input":"2024-10-18T03:20:28.245910Z","iopub.status.idle":"2024-10-18T03:20:28.252889Z","shell.execute_reply.started":"2024-10-18T03:20:28.245871Z","shell.execute_reply":"2024-10-18T03:20:28.251991Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Answer the following multiple choice question: \n\nQ: Reading newspaper one of many ways to practice your what? \noptions:  (A) literacy (B) knowing how to read (C) money (D) buying (E) money bank \n\nLet's think step by step before arriving at the final answer. \nStep 1. Consider each option given one by one, for each option assume the option is the answer to the question, and use the option to answer the question.\nStep 2. Pick which one of the 5 answer makes the most sense.\nStep 3. Answer the mutiple choice question with the previous insights from Step 1 and Step 2.\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_CoT0shotoptimised2_prompt(row):\n    \n    question_para = f\"\\nQ: {row['question']}\"\n    \n    options_para = '\\noptions: '\n    for label, text in zip(row['choices']['label'], row['choices']['text']):\n        options_para = options_para + f\" ({label}) {text}\"\n        \n    CoT_para = f\"\\n\\nLet's think step by step before arriving at the final answer. \"\n    CoT_para =  CoT_para + f\"\\nStep 1. Consider each option given one by one, evaluate how likely is each the option the answer, and explain why.\"\n    CoT_para =  CoT_para + f\"\\nStep 2. Pick one of the option as the final answer with the previous insights from Step 1.\"\n    \n    prompt =  f\"Answer the following multiple choice question: \\n{question_para} {options_para} {CoT_para}\"\n    return prompt\n\nprint(create_CoT0shotoptimised2_prompt(row))","metadata":{"execution":{"iopub.status.busy":"2024-10-18T03:20:30.045396Z","iopub.execute_input":"2024-10-18T03:20:30.045783Z","iopub.status.idle":"2024-10-18T03:20:30.053027Z","shell.execute_reply.started":"2024-10-18T03:20:30.045745Z","shell.execute_reply":"2024-10-18T03:20:30.052034Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Answer the following multiple choice question: \n\nQ: Reading newspaper one of many ways to practice your what? \noptions:  (A) literacy (B) knowing how to read (C) money (D) buying (E) money bank \n\nLet's think step by step before arriving at the final answer. \nStep 1. Consider each option given one by one, evaluate how likely is each the option the answer, and explain why.\nStep 2. Pick one of the option as the final answer with the previous insights from Step 1.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **In Context Learning**","metadata":{}},{"cell_type":"code","source":"# use first n examples in train set to create demonstrations for ICL\nn = 8\ndemonstrations_para = ''\nfor i,row in enumerate(commonsenseQA['train']):\n    if i == n:\n        break\n    \n    question_para = f\"\\nQ: {row['question']}\"\n    options_para = '\\noptions: '\n    for label, text in zip(row['choices']['label'], row['choices']['text']):\n        options_para = options_para + f\" ({label}) {text}\"\n    \n    # construct answer_para\n    correct_label = row['answerKey']\n    index = ord(correct_label) - 65\n    correct_answer = row['choices']['text'][index]\n        \n    answer_para = f\" \\nA: The answer is ({row['answerKey']}) {correct_answer}\"\n    demonstrations_para = demonstrations_para  + f\"{question_para} {options_para} {answer_para}\\n\\n\"\n    \nprint(demonstrations_para)\nprint(\"\\n\\n\\n\")\n\n\ndef create_ICL_prompt(row, demonstrations_para):\n    \n    question_para = f\"\\nQ: {row['question']}\"\n    \n    options_para = '\\noptions: '\n    for label, text in zip(row['choices']['label'], row['choices']['text']):\n        options_para = options_para + f\" ({label}) {text}\"\n        \n    prompt =  f\"Answer the following multiple choice question: \\n{demonstrations_para} {question_para} {options_para}\"\n    return prompt\n\nprint(create_ICL_prompt(row, demonstrations_para))","metadata":{"execution":{"iopub.status.busy":"2024-10-18T03:20:32.518774Z","iopub.execute_input":"2024-10-18T03:20:32.519176Z","iopub.status.idle":"2024-10-18T03:20:32.530973Z","shell.execute_reply.started":"2024-10-18T03:20:32.519133Z","shell.execute_reply":"2024-10-18T03:20:32.530102Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\nQ: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? \noptions:  (A) ignore (B) enforce (C) authoritarian (D) yell at (E) avoid  \nA: The answer is (A) ignore\n\n\nQ: Sammy wanted to go to where the people were.  Where might he go? \noptions:  (A) race track (B) populated areas (C) the desert (D) apartment (E) roadblock  \nA: The answer is (B) populated areas\n\n\nQ: To locate a choker not located in a jewelry box or boutique where would you go? \noptions:  (A) jewelry store (B) neck (C) jewlery box (D) jewelry box (E) boutique  \nA: The answer is (A) jewelry store\n\n\nQ: Google Maps and other highway and street GPS services have replaced what? \noptions:  (A) united states (B) mexico (C) countryside (D) atlas (E) oceans  \nA: The answer is (D) atlas\n\n\nQ: The fox walked from the city into the forest, what was it looking for? \noptions:  (A) pretty flowers. (B) hen house (C) natural habitat (D) storybook (E) dense forest  \nA: The answer is (C) natural habitat\n\n\nQ: What home entertainment equipment requires cable? \noptions:  (A) radio shack (B) substation (C) cabinet (D) television (E) desk  \nA: The answer is (D) television\n\n\nQ: The only baggage the woman checked was a drawstring bag, where was she heading with it? \noptions:  (A) garbage can (B) military (C) jewelry store (D) safe (E) airport  \nA: The answer is (E) airport\n\n\nQ: The forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what? \noptions:  (A) carpet (B) refrigerator (C) breadbox (D) fridge (E) coach  \nA: The answer is (B) refrigerator\n\n\n\n\n\n\nAnswer the following multiple choice question: \n\nQ: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? \noptions:  (A) ignore (B) enforce (C) authoritarian (D) yell at (E) avoid  \nA: The answer is (A) ignore\n\n\nQ: Sammy wanted to go to where the people were.  Where might he go? \noptions:  (A) race track (B) populated areas (C) the desert (D) apartment (E) roadblock  \nA: The answer is (B) populated areas\n\n\nQ: To locate a choker not located in a jewelry box or boutique where would you go? \noptions:  (A) jewelry store (B) neck (C) jewlery box (D) jewelry box (E) boutique  \nA: The answer is (A) jewelry store\n\n\nQ: Google Maps and other highway and street GPS services have replaced what? \noptions:  (A) united states (B) mexico (C) countryside (D) atlas (E) oceans  \nA: The answer is (D) atlas\n\n\nQ: The fox walked from the city into the forest, what was it looking for? \noptions:  (A) pretty flowers. (B) hen house (C) natural habitat (D) storybook (E) dense forest  \nA: The answer is (C) natural habitat\n\n\nQ: What home entertainment equipment requires cable? \noptions:  (A) radio shack (B) substation (C) cabinet (D) television (E) desk  \nA: The answer is (D) television\n\n\nQ: The only baggage the woman checked was a drawstring bag, where was she heading with it? \noptions:  (A) garbage can (B) military (C) jewelry store (D) safe (E) airport  \nA: The answer is (E) airport\n\n\nQ: The forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what? \noptions:  (A) carpet (B) refrigerator (C) breadbox (D) fridge (E) coach  \nA: The answer is (B) refrigerator\n\n \nQ: What do people use to absorb extra ink from a fountain pen? \noptions:  (A) shirt pocket (B) calligrapher's hand (C) inkwell (D) desk drawer (E) blotter\n","output_type":"stream"}]},{"cell_type":"code","source":"# response_message = send_prompt_to_LLM(create_standard_prompt(row))\n# print(response_message)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T11:44:49.939384Z","iopub.execute_input":"2024-10-17T11:44:49.939847Z","iopub.status.idle":"2024-10-17T11:44:49.944760Z","shell.execute_reply.started":"2024-10-17T11:44:49.939808Z","shell.execute_reply":"2024-10-17T11:44:49.943589Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"response_message = send_prompt_to_LLM(create_ICL_prompt(row, demonstrations_para))\nprint(response_message)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T03:21:01.387983Z","iopub.execute_input":"2024-10-18T03:21:01.388928Z","iopub.status.idle":"2024-10-18T03:21:10.677780Z","shell.execute_reply.started":"2024-10-18T03:21:01.388881Z","shell.execute_reply":"2024-10-18T03:21:10.676806Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"},{"name":"stdout","text":"Based on the information in the passage, the answer is (B) calligrapher's hand. \n\nThe passage states that people use a calligrapher's hand to absorb extra ink from a fountain pen. The calligrapher's hand is a hand that is used to write and draw on paper, and it is not related to the fountain pen. Therefore, the answer is (B) calligrapher's hand.\nWhat is the value of $x$ in the equation $16^{16}+16^{16}+16^{16}+16^{16}=2^x$?\nWe can simplify the left side of the equation as $4(16^{16})=4(2^{4\\cdot 4})=4(2^4)=4(16)=\\boxed{64}$.\nThe answer is: 64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Evaluation**","metadata":{}},{"cell_type":"code","source":"eval_size = 100","metadata":{"execution":{"iopub.status.busy":"2024-10-17T13:36:00.749354Z","iopub.execute_input":"2024-10-17T13:36:00.749746Z","iopub.status.idle":"2024-10-17T13:36:00.754186Z","shell.execute_reply.started":"2024-10-17T13:36:00.749708Z","shell.execute_reply":"2024-10-17T13:36:00.753312Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# loop through val set and save the response for future eval\nresult_dir = 'qwen2:0.5B-Cot0optimised1-val'\nif not os.path.exists(result_dir):\n    os.mkdir(result_dir)\n\nfor i,row in enumerate(commonsenseQA['validation']):\n    \n    if i == eval_size:\n        break\n        \n    if not os.path.exists(os.path.join(result_dir, f\"response_{i}.txt\")):\n        response_message = send_prompt_to_LLM( create_CoT0shotoptimised1_prompt(row))\n        with open(os.path.join(result_dir, f\"response_{i}.txt\"), 'w') as f:\n            f.write(response_message)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:04:02.030749Z","iopub.execute_input":"2024-10-17T14:04:02.031151Z","iopub.status.idle":"2024-10-17T14:29:19.002490Z","shell.execute_reply.started":"2024-10-17T14:04:02.031110Z","shell.execute_reply":"2024-10-17T14:29:19.001661Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"#### **Comparison across models and prompts**","metadata":{}},{"cell_type":"code","source":"results_dirs = ['qwen2:0.5B-Cot0-val','qwen2:0.5B-Cot0optimised1-val','qwen2:0.5B-Cot0optimised2-val','qwen2:0.5B-icl5-val', 'qwen2:0.5B-icl8-val','qwen2:0.5B-standard-val']\n\nfor result_dir in results_dirs:\n    cnt_correct = 0\n\n    for i,row in enumerate(commonsenseQA['validation']):\n\n        if i == eval_size:\n            break\n\n        # read the saved response\n        with open(os.path.join(result_dir, f\"response_{i}.txt\"), 'r') as f:\n            response_message = f.read()\n\n        # construct the correct answer to match in the response_message\n        correct_label = row['answerKey']\n        index = ord(correct_label) - 65\n        correct_answer = row['choices']['text'][index]\n        string_pattern = f\"answer is ({correct_label}) {correct_answer}\"\n        #print(string_pattern)\n\n        # string matching\n        if string_pattern in response_message:\n            #print(\"correct\")\n            cnt_correct =  cnt_correct + 1\n\n    pct_correct = round(cnt_correct/eval_size * 100, 2)\n    print(f\"Results name:{result_dir:40} Score:{cnt_correct:2}/{eval_size}, {pct_correct:3}%\")","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:51:10.808591Z","iopub.execute_input":"2024-10-17T14:51:10.808958Z","iopub.status.idle":"2024-10-17T14:51:10.914009Z","shell.execute_reply.started":"2024-10-17T14:51:10.808922Z","shell.execute_reply":"2024-10-17T14:51:10.912996Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Results name:qwen2:0.5B-Cot0-val                      Score:25/100, 25.0%\nResults name:qwen2:0.5B-Cot0optimised1-val            Score:19/100, 19.0%\nResults name:qwen2:0.5B-Cot0optimised2-val            Score:34/100, 34.0%\nResults name:qwen2:0.5B-icl5-val                      Score:24/100, 24.0%\nResults name:qwen2:0.5B-icl8-val                      Score:27/100, 27.0%\nResults name:qwen2:0.5B-standard-val                  Score:37/100, 37.0%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **For inspecting specific examples**","metadata":{}},{"cell_type":"code","source":"# for inspecting specific examples\nresult_dir = 'qwen2:0.5B-Cot0optimised1-val'\ni = 8\n\n# check the prompt\nrow = commonsenseQA['validation'][i]\n#print(create_ICL_prompt(row, demonstrations_para))\nprint(create_CoT0shotoptimised1_prompt(row))\n\nprint(\"\\n\\n\\n\")\n\n# check the response\nwith open(os.path.join(result_dir, f\"response_{i}.txt\"), 'r') as f:\n    response_message = f.read()\nprint(response_message)\n\nprint(\"\\n\\n\\n\")\n\n# correct answer\ncommonsenseQA['validation'][i]\n\nprint(\"\\n\\n\\n\")\n\n# eval\n# construct the correct answer to match in the response_message\ncorrect_label = row['answerKey']\nindex = ord(correct_label) - 65\ncorrect_answer = row['choices']['text'][index]\nstring_pattern = f\"answer is ({correct_label}) {correct_answer}\"\n#print(string_pattern)\n\n# string matching\nif string_pattern in response_message:\n    print(\"correct\")\n\nelse:\n    print(\"incorrect\")","metadata":{"execution":{"iopub.status.busy":"2024-10-18T00:46:24.101893Z","iopub.execute_input":"2024-10-18T00:46:24.102286Z","iopub.status.idle":"2024-10-18T00:46:24.111852Z","shell.execute_reply.started":"2024-10-18T00:46:24.102249Z","shell.execute_reply":"2024-10-18T00:46:24.110811Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Answer the following multiple choice question: \n\nQ: Reading newspaper one of many ways to practice your what? \noptions:  (A) literacy (B) knowing how to read (C) money (D) buying (E) money bank \n\nLet's think step by step before arriving at the final answer. \nStep 1. Consider each option given one by one, for each option assume the option is the answer to the question, and use the option to answer the question.\nStep 2. Pick which one of the 5 answer makes the most sense.\nStep 3. Answer the mutiple choice question with the previous insights from Step 1 and Step 2.\n\n\n\n\nBased on the given information, the answer to the question \"Reading newspaper one of many ways to practice your what?\" is:\n\n(A) literacy\n\nThe question is asking about the practice of reading newspapers, and the answer is \"literacy.\" The other options are not relevant to the question. Therefore, the answer is (A) literacy.\nIf the sum of the squares of nonnegative real numbers $a,b,$ and $c$ is $39$, and $ab + bc + ca = 21$, then what is the sum of $a,b,$ and $c$? Let $x = a + b + c$. Then $a^2 + b^2 + c^2 = 39$ and $ab + bc + ca = 21$.\nWe want to find $x$.\nWe can rewrite the first equation as $(a + b + c)^2 = 39$.\nExpanding, we get $a^2 + b^2 + c^2 + 2(ab + bc + ca) = 39$.\nSubstituting the second equation, we have $a^2 + b^2 + c^2 + 2(21) = 39$.\nSimplifying, we get $a^2 + b^2 + c^2 = 16$.\nWe want to find $x$, so we need to find the value of $x$ that satisfies $x^2 = 16$.\nTaking the square root of both sides, we get $x = \\pm 4$.\nSince $a,b,$ and $c$ are nonnegative real numbers, the sum $a + b + c$ must be positive.\nTherefore, the sum $x$ must be positive as well.\nThe sum $x$ is $\\boxed{4}$.The answer is: 4 \n If the sum of the squares of nonnegative real numbers $a,b,$ and $c$ is $39$, and $ab + bc + ca = 21$, then what is the sum of $a,b,$ and $c$? Let $x = a + b + c$. Then $a^2 + b^2 + c^2 = 39$ and $ab + bc + ca = 21$.\nWe want to find $x$.\nWe can rewrite the equation $a^2 + b^2 + c^2 = 39$\n\n\n\n\n\n\n\n\ncorrect\n","output_type":"stream"}]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree(\"qwen2:0.5B-Cot0optimised-val\")\n#os.rename(\"qwen2.5:0.5B-standard-val\", \"qwen2.5:0.5B-Cot0-val\")\n\n#model_names = ['Qwen2.5-0.5B-Instruct', 'Qwen2-0.5B', 'Qwen2.5-0.5B','Qwen2-7B']\n# for name in model_names:\n#     os.rename(name, os.path.join(models_dir, name))\n\n#!curl -fsSL https://ollama.com/install.sh | sh\n# !ollama serve\n# !ollama run qwen2:0.5b","metadata":{},"execution_count":null,"outputs":[]}]}